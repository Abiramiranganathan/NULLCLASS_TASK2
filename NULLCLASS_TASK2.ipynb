{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8557139-1f5b-49a3-b406-8bbd357ef05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.1-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.1 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3408742-afde-4bc3-923e-a85bee7a823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (2.3.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (5.29.5)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (2.32.4)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (4.14.1)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abira\\anaconda3\\envs\\tfenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.9 MB 1.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.8/9.9 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 1.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 1.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.8/9.9 MB 1.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.1/9.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.4/9.9 MB 1.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.7/9.9 MB 1.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.9/9.9 MB 1.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.5/9.9 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.7/9.9 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.2/9.9 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.0/9.9 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.3/9.9 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.6/9.9 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.8/9.9 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 1.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.6/9.9 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.9/9.9 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.4/9.9 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/9.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 3.4 MB/s eta 0:00:00\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.9 MB 2.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.6/6.9 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.4/6.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/6.9 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading narwhals-2.0.1-py3-none-any.whl (385 kB)\n",
      "Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/26.2 MB 10.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.9/26.2 MB 10.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.0/26.2 MB 10.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/26.2 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.4/26.2 MB 9.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.5/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.8/26.2 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.1/26.2 MB 8.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.2/26.2 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.2/26.2 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.5/26.2 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.2 MB 7.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.9/26.2 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.4/26.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.5/26.2 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.6/26.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl (231 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, rpds-py, pyarrow, narwhals, cachetools, blinker, attrs, referencing, pydeck, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\n",
      "   -- -------------------------------------  1/18 [toml]\n",
      "   -------- -------------------------------  4/18 [rpds-py]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ----------- ----------------------------  5/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [narwhals]\n",
      "   ------------- --------------------------  6/18 [narwhals]\n",
      "   ------------- --------------------------  6/18 [narwhals]\n",
      "   ------------- --------------------------  6/18 [narwhals]\n",
      "   ------------- --------------------------  6/18 [narwhals]\n",
      "   ------------- --------------------------  6/18 [narwhals]\n",
      "   --------------- ------------------------  7/18 [cachetools]\n",
      "   -------------------- -------------------  9/18 [attrs]\n",
      "   ------------------------ --------------- 11/18 [pydeck]\n",
      "   ------------------------ --------------- 11/18 [pydeck]\n",
      "   -------------------------- ------------- 12/18 [gitdb]\n",
      "   ---------------------------- ----------- 13/18 [jsonschema-specifications]\n",
      "   ------------------------------- -------- 14/18 [gitpython]\n",
      "   ------------------------------- -------- 14/18 [gitpython]\n",
      "   --------------------------------- ------ 15/18 [jsonschema]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ---------------------------------------- 18/18 [streamlit]\n",
      "\n",
      "Successfully installed altair-5.5.0 attrs-25.3.0 blinker-1.9.0 cachetools-6.1.0 gitdb-4.0.12 gitpython-3.1.45 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 narwhals-2.0.1 pyarrow-21.0.0 pydeck-0.9.1 referencing-0.36.2 rpds-py-0.26.0 smmap-5.0.2 streamlit-1.47.1 tenacity-9.1.2 toml-0.10.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script watchmedo.exe is installed in 'C:\\Users\\abira\\anaconda3\\envs\\tfenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema.exe is installed in 'C:\\Users\\abira\\anaconda3\\envs\\tfenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script streamlit.exe is installed in 'C:\\Users\\abira\\anaconda3\\envs\\tfenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8785e2cc-1eda-4d90-9988-f74a5c4aa7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Processing folder: 10_MPlus_ADAM_QA\n",
      "📁 Processing folder: 11_MPlusDrugs_QA\n",
      "📁 Processing folder: 12_MPlusHerbsSupplements_QA\n",
      "📁 Processing folder: 1_CancerGov_QA\n",
      "📁 Processing folder: 2_GARD_QA\n",
      "📁 Processing folder: 3_GHR_QA\n",
      "📁 Processing folder: 4_MPlus_Health_Topics_QA\n",
      "📁 Processing folder: 5_NIDDK_QA\n",
      "📁 Processing folder: 6_NINDS_QA\n",
      "📁 Processing folder: 7_SeniorHealth_QA\n",
      "📁 Processing folder: 9_CDC_QA\n",
      "\n",
      " Combined CSV saved: C:\\Users\\abira\\OneDrive\\downloads\\MedQuAD-master\\MedQuAD-master\\All_MedQuAD_QA.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "#  Change this to your MedQuAD base folder\n",
    "base_dir = \"C:\\\\Users\\\\abira\\\\OneDrive\\\\downloads\\\\MedQuAD-master\\\\MedQuAD-master\"\n",
    "\n",
    "all_data = []  # List to store all Q-A pairs\n",
    "\n",
    "# Function to recursively extract full text from nested XML elements\n",
    "def get_full_text(element):\n",
    "    return ''.join(element.itertext()).strip() if element is not None else \"\"\n",
    "\n",
    "# Loop through each _QA folder\n",
    "for folder in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    if os.path.isdir(folder_path) and folder.endswith(\"_QA\"):\n",
    "        print(f\"📁 Processing folder: {folder}\")\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if file_name.endswith(\".xml\") or file_name.isdigit():\n",
    "                try:\n",
    "                    tree = ET.parse(file_path)\n",
    "                    root = tree.getroot()\n",
    "\n",
    "                    # Get URL from the root tag\n",
    "                    url = root.attrib.get('url', '')\n",
    "\n",
    "                    # Loop through each QAPair\n",
    "                    for qapair in root.iter():\n",
    "                        if \"qapair\" in qapair.tag.lower():\n",
    "                            q = a = \"\"\n",
    "                            for child in qapair:\n",
    "                                tag = child.tag.lower()\n",
    "                                if \"question\" in tag:\n",
    "                                    q = child.text.strip() if child.text else \"\"\n",
    "                                elif \"answer\" in tag:\n",
    "                                    a = get_full_text(child)  \n",
    "                            if q: \n",
    "                                all_data.append({\n",
    "                                    \"Folder\": folder,\n",
    "                                    \"File\": file_name,\n",
    "                                    \"Question\": q,\n",
    "                                    \"Answer\": a,\n",
    "                                    \"URL\": url\n",
    "                                })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠ Error in {folder}/{file_name}: {e}\")\n",
    "\n",
    "# Save combined CSV if data was extracted\n",
    "if all_data:\n",
    "    df_all = pd.DataFrame(all_data)\n",
    "    output_path = os.path.join(base_dir, \"All_MedQuAD_QA.csv\")\n",
    "    df_all.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    print(f\"\\n Combined CSV saved: {output_path}\")\n",
    "else:\n",
    "    print(\"\\n No data extracted from any folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c8c9a6-86f1-4b63-9b6f-3837da4662b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved at: C:\\Users\\abira\\OneDrive\\downloads\\MedQuAD-master\\MedQuAD-master\\All_MedQuAD_QA_Cleaned.csv\n",
      "Total rows after cleaning: 15800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "# Path to your dataset\n",
    "\n",
    "file_path = r\"C:\\Users\\abira\\OneDrive\\downloads\\MedQuAD-master\\MedQuAD-master\\All_MedQuAD_QA.csv\"\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text)   \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Cleaning steps\n",
    "# Drop rows with missing or empty Question/Answer\n",
    "df = df.dropna(subset=[\"Question\", \"Answer\"])\n",
    "df = df[df[\"Question\"].str.strip() != \"\"]\n",
    "df = df[df[\"Answer\"].str.strip() != \"\"]\n",
    "\n",
    "# Apply cleaning\n",
    "df[\"Question\"] = df[\"Question\"].apply(clean_text)\n",
    "df[\"Answer\"] = df[\"Answer\"].apply(clean_text)\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates(subset=[\"Question\", \"Answer\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Save cleaned dataset\n",
    "dir_name = os.path.dirname(file_path)\n",
    "save_path = os.path.join(dir_name, \"All_MedQuAD_QA_Cleaned.csv\")\n",
    "df.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ Cleaned dataset saved at: {save_path}\")\n",
    "print(f\"Total rows after cleaning: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46dee52-afc3-41f4-bcfb-821b7a5d639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 19:59:21.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.303 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.303 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.303 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-10 19:59:21.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Load cleaned dataset\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\abira\\OneDrive\\downloads\\MedQuAD-master\\MedQuAD-master\\All_MedQuAD_QA_Cleaned.csv\"\n",
    ")\n",
    "\n",
    "# Extract questions and answers\n",
    "questions = df[\"Question\"].values\n",
    "answers = df[\"Answer\"].values\n",
    "\n",
    "\n",
    "# Fit TF-IDF vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "question_vectors = vectorizer.fit_transform(questions)\n",
    "\n",
    "\n",
    "# Simple list of medical keywords for basic entity recognition\n",
    "medical_keywords = [\n",
    "    \"asthma\", \"cancer\", \"diabetes\", \"infection\", \"fever\", \"headache\", \"surgery\", \"tumor\",\n",
    "    \"symptom\", \"treatment\", \"medication\", \"disease\", \"nausea\", \"pain\", \"blood pressure\"\n",
    "]\n",
    "\n",
    "\n",
    "# Streamlit UI\n",
    "\n",
    "st.title(\"🩺 Medical Q&A Chatbot\")\n",
    "st.write(\"Ask any medical question and get reliable answers from the MedQuAD dataset.\")\n",
    "\n",
    "user_input = st.text_input(\"Enter your medical question:\")\n",
    "\n",
    "if user_input:\n",
    "    # Entity recognition (basic)\n",
    "    detected_entities = [word for word in medical_keywords if word in user_input.lower()]\n",
    "\n",
    "    # Similarity-based retrieval\n",
    "    user_vector = vectorizer.transform([user_input])\n",
    "    similarities = cosine_similarity(user_vector, question_vectors).flatten()\n",
    "    best_match_index = similarities.argmax()\n",
    "\n",
    "    # Display best match\n",
    "    st.subheader(\"🔍 Best Match:\")\n",
    "    st.markdown(f\"**Q:** {questions[best_match_index]}\")\n",
    "    st.markdown(f\"**A:** {answers[best_match_index]}\")\n",
    "\n",
    "    # Show detected medical entities\n",
    "    if detected_entities:\n",
    "        st.subheader(\"🧠 Detected Medical Entities:\")\n",
    "        st.write(\", \".join(detected_entities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47ca963-8fee-4b37-a5ea-855775aa8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run in cmd \n",
    "# cd \"C:\\Users\\abira\\OneDrive\\Downloads\\MedQuAD-master\\MedQuAD-master\"\n",
    "# streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14b0709-47d4-4dff-b0e0-7584e7d006a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Accuracy: 90.00% (18/20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\abira\\OneDrive\\downloads\\MedQuAD-master\\MedQuAD-master\\All_MedQuAD_QA_Cleaned.csv\")\n",
    "\n",
    "\n",
    "# Fit vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "question_vectors = vectorizer.fit_transform(df[\"Question\"])\n",
    "\n",
    "\n",
    "# Function to get best match\n",
    "def get_best_match(query):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, question_vectors).flatten()\n",
    "    best_index = similarities.argmax()\n",
    "    return df.iloc[best_index][\"Answer\"]\n",
    "\n",
    "\n",
    "# Accuracy Test\n",
    "# Pick random 20 questions from dataset for testing\n",
    "\n",
    "test_samples = df.sample(20, random_state=42)\n",
    "\n",
    "correct = 0\n",
    "for _, row in test_samples.iterrows():\n",
    "    query = row[\"Question\"]\n",
    "    expected_answer = row[\"Answer\"]\n",
    "    predicted_answer = get_best_match(query)\n",
    "    \n",
    "    # Check exact match\n",
    "    if predicted_answer.strip().lower() == expected_answer.strip().lower():\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(test_samples)\n",
    "print(f\"Retrieval Accuracy: {accuracy*100:.2f}% ({correct}/{len(test_samples)})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
